=> fetching img pairs in /data2/datasets/ruoguli/PS_Blobby_Dataset
	 Found Data: 25661 Train and 259 Val
	 Train Batch 64, Val Batch: 8
Creating Model PS_FCN_FiLM
[Network Input] Color image as input
[Network Input] Adding Light direction as input
[Network Input] Input channel: 6
Conv pad = 1
Conv pad = 1
Conv pad = 1
Conv pad = 1
Conv pad = 1
Conv pad = 1
=> using pre-trained model /data2/datasets/ruoguli/idl_project_datas/PS-FCN_B_S_32.pth.tar
Detailed loading log saved to: logs/loading_log_20250416-151526.txt
PS_FCN_FiLM(
  (brdf_embed_block): BRDF_EmbedBlock(
    (embed_transform): Sequential(
      (0): Linear(in_features=14, out_features=512, bias=True)
      (1): LeakyReLU(negative_slope=0.1)
    )
  )
  (extractor): FeatExtractor(
    (conv1): FiLMConv(
      (conv): Conv2d(6, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): LeakyReLU(negative_slope=0.1, inplace=True)
      (FiLMGnerator): Linear(in_features=512, out_features=128, bias=True)
      (FiLMBlock): FiLMBlock()
    )
    (conv2): FiLMConv(
      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (relu): LeakyReLU(negative_slope=0.1, inplace=True)
      (FiLMGnerator): Linear(in_features=512, out_features=256, bias=True)
      (FiLMBlock): FiLMBlock()
    )
    (conv3): FiLMConv(
      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): LeakyReLU(negative_slope=0.1, inplace=True)
      (FiLMGnerator): Linear(in_features=512, out_features=256, bias=True)
      (FiLMBlock): FiLMBlock()
    )
    (conv4): FiLMConv(
      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (relu): LeakyReLU(negative_slope=0.1, inplace=True)
      (FiLMGnerator): Linear(in_features=512, out_features=512, bias=True)
      (FiLMBlock): FiLMBlock()
    )
    (conv5): FiLMConv(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): LeakyReLU(negative_slope=0.1, inplace=True)
      (FiLMGnerator): Linear(in_features=512, out_features=512, bias=True)
      (FiLMBlock): FiLMBlock()
    )
    (conv6): Sequential(
      (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
      (1): LeakyReLU(negative_slope=0.1, inplace=True)
    )
    (conv7): Sequential(
      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): LeakyReLU(negative_slope=0.1, inplace=True)
    )
  )
  (regressor): Regressor(
    (deconv1): Sequential(
      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): LeakyReLU(negative_slope=0.1, inplace=True)
    )
    (deconv2): Sequential(
      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): LeakyReLU(negative_slope=0.1, inplace=True)
    )
    (deconv3): Sequential(
      (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
      (1): LeakyReLU(negative_slope=0.1, inplace=True)
    )
    (est_normal): Sequential(
      (0): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
=> Model Parameters: 3071360
=> Using adam solver for optimization
=> Using cos for criterion normal
---- Start Training Epoch 1: 401 batches ----
---- Start val Epoch 1: 33 batches ----
Save epoch model at 1
Epoch 1: train_loss 0.2781, val_n_err 5.7200
---- Start Training Epoch 2: 401 batches ----
---- Start val Epoch 2: 33 batches ----
Save epoch model at 2
Epoch 2: train_loss 0.2729, val_n_err 5.0874
---- Start Training Epoch 3: 401 batches ----
---- Start val Epoch 3: 33 batches ----
Save epoch model at 3
Epoch 3: train_loss 0.2735, val_n_err 5.1155
---- Start Training Epoch 4: 401 batches ----
---- Start val Epoch 4: 33 batches ----
Save epoch model at 4
Epoch 4: train_loss 0.2738, val_n_err 5.2531
---- Start Training Epoch 5: 401 batches ----
---- Start val Epoch 5: 33 batches ----
Best model saved at epoch 5
Save epoch model at 5
Epoch 5: train_loss 0.2740, val_n_err 4.7660
---- Start Training Epoch 6: 401 batches ----
---- Start val Epoch 6: 33 batches ----
Save epoch model at 6
Epoch 6: train_loss 0.2737, val_n_err 5.1990
---- Start Training Epoch 7: 401 batches ----
---- Start val Epoch 7: 33 batches ----
Save epoch model at 7
Epoch 7: train_loss 0.2731, val_n_err 5.0296
---- Start Training Epoch 8: 401 batches ----
---- Start val Epoch 8: 33 batches ----
Best model saved at epoch 8
Save epoch model at 8
Epoch 8: train_loss 0.2753, val_n_err 4.7134
---- Start Training Epoch 9: 401 batches ----
---- Start val Epoch 9: 33 batches ----
Save epoch model at 9
Epoch 9: train_loss 0.2721, val_n_err 4.7737
---- Start Training Epoch 10: 401 batches ----
---- Start val Epoch 10: 33 batches ----
Save epoch model at 10
Epoch 10: train_loss 0.2722, val_n_err 4.9196
---- Start Training Epoch 11: 401 batches ----
---- Start val Epoch 11: 33 batches ----
Save epoch model at 11
Epoch 11: train_loss 0.2723, val_n_err 4.7898
---- Start Training Epoch 12: 401 batches ----
---- Start val Epoch 12: 33 batches ----
Best model saved at epoch 12
Save epoch model at 12
Epoch 12: train_loss 0.2717, val_n_err 4.5955
---- Start Training Epoch 13: 401 batches ----
---- Start val Epoch 13: 33 batches ----
Save epoch model at 13
Epoch 13: train_loss 0.2727, val_n_err 4.9371
---- Start Training Epoch 14: 401 batches ----
---- Start val Epoch 14: 33 batches ----
Save epoch model at 14
Epoch 14: train_loss 0.2739, val_n_err 4.6822
---- Start Training Epoch 15: 401 batches ----
---- Start val Epoch 15: 33 batches ----
Save epoch model at 15
Epoch 15: train_loss 0.2730, val_n_err 4.6665
---- Start Training Epoch 16: 401 batches ----
---- Start val Epoch 16: 33 batches ----
Save epoch model at 16
Epoch 16: train_loss 0.2702, val_n_err 4.6833
---- Start Training Epoch 17: 401 batches ----
---- Start val Epoch 17: 33 batches ----
Best model saved at epoch 17
Save epoch model at 17
Epoch 17: train_loss 0.2729, val_n_err 4.5275
---- Start Training Epoch 18: 401 batches ----
---- Start val Epoch 18: 33 batches ----
Best model saved at epoch 18
Save epoch model at 18
Epoch 18: train_loss 0.2714, val_n_err 4.5252
---- Start Training Epoch 19: 401 batches ----
---- Start val Epoch 19: 33 batches ----
Save epoch model at 19
Epoch 19: train_loss 0.2725, val_n_err 4.5843
---- Start Training Epoch 20: 401 batches ----
