=> Using adam solver for optimization
=> Using cos for criterion normal
/data2/datasets/ruoguli/miniconda/envs/torch_env/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
/data2/datasets/ruoguli/miniconda/envs/torch_env/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:595: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  _warn_get_lr_called_within_step(self)
---- Start val Epoch 1: 33 batches ----
Val:   0%|                                            | 0/33 [00:00<?, ?it/s]/home/ruoguli/idl_project/utils/eval_utils.py:12: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at /opt/conda/conda-bld/pytorch_1729647329220/work/aten/src/ATen/native/IndexingUtils.h:27.)
  ang_valid   = angular_map[mask.narrow(1, 0, 1).squeeze(1).byte()]
Traceback (most recent call last):                                           
> /home/ruoguli/idl_project/train_PSFCN.py(37)main()
-> for epoch in range(args.start_epoch, args.epochs+1):
 32  	        load_wandb(args, model)
 33  	    optimizer, scheduler, records = solver_utils.configOptimizer(args, model)
 34  	    criterion = solver_utils.Criterion(args)
 35  	    recorder  = recorders.Records(args.log_dir, records)
 36  	
 37  ->	    for epoch in range(args.start_epoch, args.epochs+1):
 38  	        scheduler.step()
 39  	        recorder.insertRecord('train', 'lr', epoch, scheduler.get_lr()[0])
 40  	
 41  	        # train_opt = train_utils.train(args, train_loader, model, criterion, optimizer, log, epoch, recorder)
 42  	        # if epoch % args.save_intv == 0:
{'split': 'val', 'epoch': 1, 'recorder': <utils.recorders.Records object at 0x7f7a08b7d310>}
<utils.recorders.Records object at 0x7f7a08b7d310>
OrderedDict({'train': OrderedDict({'lr': OrderedDict({1: [0.001]})})})
OrderedDict({'train': OrderedDict({'lr': OrderedDict({1: [0.001]})})})
  File "/home/ruoguli/idl_project/train_PSFCN.py", line 51, in <module>
    main(args)
  File "/home/ruoguli/idl_project/train_PSFCN.py", line 37, in main
    for epoch in range(args.start_epoch, args.epochs+1):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data2/datasets/ruoguli/miniconda/envs/torch_env/lib/python3.12/bdb.py", line 100, in trace_dispatch
    return self.dispatch_line(frame)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data2/datasets/ruoguli/miniconda/envs/torch_env/lib/python3.12/bdb.py", line 125, in dispatch_line
    if self.quitting: raise BdbQuit
                      ^^^^^^^^^^^^^
bdb.BdbQuit
